{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69a72ac6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string expression part cannot include a backslash (2242483259.py, line 326)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 326\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"{'Feature':<20} {'KS Statistic':<15} {'KS p-value':<15} {'Jensen-Shannon':<15} {'Earth Mover\\'s Dist':<15}\")\u001b[0m\n\u001b[0m                                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string expression part cannot include a backslash\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import wasserstein_distance, chi2_contingency, fisher_exact\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "def calculate_metrics_numerical(real_values, synth_values):\n",
    "    \"\"\"\n",
    "    Calculate statistical distance metrics between real and synthetic distributions\n",
    "    for numerical features.\n",
    "    \n",
    "    Args:\n",
    "        real_values: Array of values from the real dataset\n",
    "        synth_values: Array of values from the synthetic dataset\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with calculated metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Calculate Kolmogorov-Smirnov statistic\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ks_stat, ks_pval = stats.ks_2samp(real_values, synth_values)\n",
    "    metrics['ks_statistic'] = ks_stat\n",
    "    metrics['ks_pvalue'] = ks_pval\n",
    "    \n",
    "    # Calculate Earth Mover's Distance (Wasserstein metric)\n",
    "    emd = wasserstein_distance(real_values, synth_values)\n",
    "    metrics['earth_movers_distance'] = emd\n",
    "    \n",
    "    # Calculate Jensen-Shannon Divergence for numerical data\n",
    "    min_val = min(np.min(real_values), np.min(synth_values))\n",
    "    max_val = max(np.max(real_values), np.max(synth_values))\n",
    "    bins = np.linspace(min_val, max_val, min(50, len(np.unique(np.concatenate([real_values, synth_values])))))\n",
    "    \n",
    "    # Get histogram counts and normalize\n",
    "    real_hist, _ = np.histogram(real_values, bins=bins, density=True)\n",
    "    synth_hist, _ = np.histogram(synth_values, bins=bins, density=True)\n",
    "    \n",
    "    # Handle zero frequencies by adding a small epsilon\n",
    "    epsilon = 1e-10\n",
    "    real_hist = real_hist + epsilon\n",
    "    synth_hist = synth_hist + epsilon\n",
    "    \n",
    "    # Normalize to make proper probability distributions\n",
    "    real_hist = real_hist / np.sum(real_hist)\n",
    "    synth_hist = synth_hist / np.sum(synth_hist)\n",
    "    \n",
    "    js_div = jensenshannon(real_hist, synth_hist)\n",
    "    metrics['jensen_shannon'] = js_div\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def calculate_metrics_categorical(real_values, synth_values):\n",
    "    \"\"\"\n",
    "    Calculate statistical distance metrics between real and synthetic distributions\n",
    "    for categorical features.\n",
    "    \n",
    "    Args:\n",
    "        real_values: Array of values from the real dataset\n",
    "        synth_values: Array of values from the synthetic dataset\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with calculated metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Get all unique categories\n",
    "    all_categories = np.unique(np.concatenate([real_values, synth_values]))\n",
    "    \n",
    "    # Create contingency table\n",
    "    contingency_table = np.zeros((2, len(all_categories)))\n",
    "    \n",
    "    for i, cat in enumerate(all_categories):\n",
    "        contingency_table[0, i] = np.sum(real_values == cat)\n",
    "        contingency_table[1, i] = np.sum(synth_values == cat)\n",
    "    \n",
    "    # Perform Chi-Square test\n",
    "    if np.all(contingency_table > 0) and len(all_categories) > 1:\n",
    "        chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "        metrics['chi2_statistic'] = chi2\n",
    "        metrics['chi2_pvalue'] = p_value\n",
    "    else:\n",
    "        metrics['chi2_statistic'] = np.nan\n",
    "        metrics['chi2_pvalue'] = np.nan\n",
    "    \n",
    "    # Perform Fisher's Exact test if possible (only for 2x2 tables)\n",
    "    if len(all_categories) == 2:\n",
    "        try:\n",
    "            odds_ratio, p_value = fisher_exact(contingency_table)\n",
    "            metrics['fisher_pvalue'] = p_value\n",
    "            metrics['fisher_odds_ratio'] = odds_ratio\n",
    "        except:\n",
    "            metrics['fisher_pvalue'] = np.nan\n",
    "            metrics['fisher_odds_ratio'] = np.nan\n",
    "    else:\n",
    "        metrics['fisher_pvalue'] = np.nan\n",
    "        metrics['fisher_odds_ratio'] = np.nan\n",
    "    \n",
    "    # Calculate G-test (Log-Likelihood ratio)\n",
    "    if np.all(contingency_table > 0) and len(all_categories) > 1:\n",
    "        # G-test calculation\n",
    "        observed = contingency_table.flatten()\n",
    "        row_sums = contingency_table.sum(axis=1).reshape(-1, 1)\n",
    "        col_sums = contingency_table.sum(axis=0).reshape(1, -1)\n",
    "        total = contingency_table.sum()\n",
    "        expected = np.dot(row_sums, col_sums) / total\n",
    "        expected = expected.flatten()\n",
    "        \n",
    "        g_stat = 2 * np.sum(observed * np.log(observed / expected))\n",
    "        g_pvalue = 1 - stats.chi2.cdf(g_stat, dof)\n",
    "        \n",
    "        metrics['g_test_statistic'] = g_stat\n",
    "        metrics['g_test_pvalue'] = g_pvalue\n",
    "    else:\n",
    "        metrics['g_test_statistic'] = np.nan\n",
    "        metrics['g_test_pvalue'] = np.nan\n",
    "    \n",
    "    # Calculate Jensen-Shannon Divergence for categorical data\n",
    "    real_counts = np.zeros(len(all_categories))\n",
    "    synth_counts = np.zeros(len(all_categories))\n",
    "    \n",
    "    for i, cat in enumerate(all_categories):\n",
    "        real_counts[i] = np.sum(real_values == cat) / len(real_values)\n",
    "        synth_counts[i] = np.sum(synth_values == cat) / len(synth_values)\n",
    "    \n",
    "    # Handle zero frequencies by adding a small epsilon\n",
    "    epsilon = 1e-10\n",
    "    real_counts = real_counts + epsilon\n",
    "    synth_counts = synth_counts + epsilon\n",
    "    \n",
    "    # Normalize to make proper probability distributions\n",
    "    real_counts = real_counts / np.sum(real_counts)\n",
    "    synth_counts = synth_counts / np.sum(synth_counts)\n",
    "    \n",
    "    js_div = jensenshannon(real_counts, synth_counts)\n",
    "    metrics['jensen_shannon'] = js_div\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def analyze_file(file_path, target_feature='income', target_value='>50K', \n",
    "                 synthetic_feature='synthetic', output_dir=None, plot=False):\n",
    "    \"\"\"\n",
    "    Analyze a single CSV file comparing real vs synthetic distributions.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "        target_feature: Column name for the target feature (default: 'income')\n",
    "        target_value: Value in target feature to filter for (default: '>50K')\n",
    "        synthetic_feature: Column name indicating if a record is synthetic (default: 'synthetic')\n",
    "        output_dir: Directory to save plots to (if plot=True)\n",
    "        plot: Whether to generate distribution plots\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with analysis results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        return {'file': os.path.basename(file_path), 'error': str(e)}\n",
    "    \n",
    "    # Check required columns\n",
    "    if target_feature not in df.columns or synthetic_feature not in df.columns:\n",
    "        return {'file': os.path.basename(file_path), \n",
    "                'error': f\"Missing required columns '{target_feature}' or '{synthetic_feature}'\"}\n",
    "    \n",
    "    # Convert synthetic column to boolean if it's 'yes'/'no'\n",
    "    if df[synthetic_feature].dtype == object:\n",
    "        df[synthetic_feature] = df[synthetic_feature].apply(lambda x: 1 if str(x).lower() == 'yes' else 0)\n",
    "    \n",
    "    # Filter for target value\n",
    "    if df[target_feature].dtype == object:\n",
    "        df_filtered = df[df[target_feature].str.contains(target_value, case=False, na=False)]\n",
    "    else:\n",
    "        df_filtered = df[df[target_feature] == target_value]\n",
    "    \n",
    "    if len(df_filtered) == 0:\n",
    "        return {'file': os.path.basename(file_path), \n",
    "                'error': f\"No instances with {target_feature}={target_value} found\"}\n",
    "    \n",
    "    # Separate real and synthetic samples\n",
    "    real_samples = df_filtered[df_filtered[synthetic_feature] == 0]\n",
    "    synthetic_samples = df_filtered[df_filtered[synthetic_feature] == 1]\n",
    "    \n",
    "    if len(real_samples) == 0 or len(synthetic_samples) == 0:\n",
    "        return {'file': os.path.basename(file_path), \n",
    "                'error': f\"Missing real or synthetic samples with {target_feature}={target_value}\"}\n",
    "    \n",
    "    # Define numeric and categorical features\n",
    "    numeric_features = ['age', 'fnlwgt', 'education_num', 'capital_gain', \n",
    "                        'capital_loss', 'hours_per_week']\n",
    "    categorical_features = ['workclass', 'education', 'marital_status', 'occupation', \n",
    "                           'relationship', 'race', 'sex', 'native_country']\n",
    "    \n",
    "    # Filter out target and synthetic features, and missing features\n",
    "    numeric_features = [f for f in numeric_features \n",
    "                        if f in df.columns and f != target_feature and f != synthetic_feature]\n",
    "    categorical_features = [f for f in categorical_features \n",
    "                           if f in df.columns and f != target_feature and f != synthetic_feature]\n",
    "    \n",
    "    results = {'file': os.path.basename(file_path), 'numeric': {}, 'categorical': {}}\n",
    "    \n",
    "    # Process numeric features\n",
    "    for feature in numeric_features:\n",
    "        real_values = real_samples[feature].dropna().values\n",
    "        synth_values = synthetic_samples[feature].dropna().values\n",
    "        \n",
    "        if len(real_values) < 2 or len(synth_values) < 2:\n",
    "            continue\n",
    "        \n",
    "        metrics = calculate_metrics_numerical(real_values, synth_values)\n",
    "        results['numeric'][feature] = metrics\n",
    "        \n",
    "        # Create distribution plots if requested\n",
    "        if plot and output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.hist(real_values, bins=30, alpha=0.5, label='Real', density=True)\n",
    "            plt.hist(synth_values, bins=30, alpha=0.5, label='Synthetic', density=True)\n",
    "            plt.title(f'Distribution of {feature} - {os.path.basename(file_path)}')\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f\"{os.path.basename(file_path).split('.')[0]}_{feature}_dist.png\"))\n",
    "            plt.close()\n",
    "    \n",
    "    # Process categorical features\n",
    "    for feature in categorical_features:\n",
    "        real_values = real_samples[feature].dropna().values\n",
    "        synth_values = synthetic_samples[feature].dropna().values\n",
    "        \n",
    "        if len(real_values) < 2 or len(synth_values) < 2:\n",
    "            continue\n",
    "        \n",
    "        metrics = calculate_metrics_categorical(real_values, synth_values)\n",
    "        results['categorical'][feature] = metrics\n",
    "        \n",
    "        # Create bar plots for categorical features if requested\n",
    "        if plot and output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            # Get value counts\n",
    "            real_counts = pd.Series(real_values).value_counts(normalize=True)\n",
    "            synth_counts = pd.Series(synth_values).value_counts(normalize=True)\n",
    "            \n",
    "            # Align indices\n",
    "            all_categories = sorted(set(real_counts.index) | set(synth_counts.index))\n",
    "            real_counts = real_counts.reindex(all_categories, fill_value=0)\n",
    "            synth_counts = synth_counts.reindex(all_categories, fill_value=0)\n",
    "            \n",
    "            # Plot\n",
    "            x = np.arange(len(all_categories))\n",
    "            width = 0.35\n",
    "            \n",
    "            plt.bar(x - width/2, real_counts, width, label='Real')\n",
    "            plt.bar(x + width/2, synth_counts, width, label='Synthetic')\n",
    "            \n",
    "            plt.xlabel('Categories')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.title(f'Distribution of {feature} - {os.path.basename(file_path)}')\n",
    "            plt.xticks(x, all_categories, rotation=90)\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f\"{os.path.basename(file_path).split('.')[0]}_{feature}_dist.png\"))\n",
    "            plt.close()\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_distributions(csv_files, target_feature='income', target_value='>50K', \n",
    "                          synthetic_feature='synthetic', output_dir=None, plot=False):\n",
    "    \"\"\"\n",
    "    Analyze multiple CSV files and compute statistical distance metrics.\n",
    "    \n",
    "    Args:\n",
    "        csv_files: List of paths to CSV files\n",
    "        target_feature: Column name for the target feature (default: 'income')\n",
    "        target_value: Value in target feature to filter for (default: '>50K')\n",
    "        synthetic_feature: Column name indicating if a record is synthetic (default: 'synthetic')\n",
    "        output_dir: Directory to save plots to (if plot=True)\n",
    "        plot: Whether to generate distribution plots\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries with analysis results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for file_path in csv_files:\n",
    "        print(f\"Processing {file_path}...\")\n",
    "        file_results = analyze_file(\n",
    "            file_path, \n",
    "            target_feature=target_feature, \n",
    "            target_value=target_value,\n",
    "            synthetic_feature=synthetic_feature,\n",
    "            output_dir=output_dir, \n",
    "            plot=plot\n",
    "        )\n",
    "        results.append(file_results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_results_detailed(results):\n",
    "    \"\"\"\n",
    "    Print detailed analysis results in a tabular format without tabulate.\n",
    "    \n",
    "    Args:\n",
    "        results: List of dictionaries with analysis results\n",
    "    \"\"\"\n",
    "    for result in results:\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(f\"File: {result['file']}\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        if 'error' in result:\n",
    "            print(f\"ERROR: {result['error']}\")\n",
    "            continue\n",
    "        \n",
    "        # Print numerical features\n",
    "        if result['numeric']:\n",
    "            print(\"\\nNUMERICAL FEATURES\")\n",
    "            print(\"-\"*100)\n",
    "            \n",
    "            # Print header\n",
    "            print(f\"{'Feature':<20} {'KS Statistic':<15} {'KS p-value':<15} {'Jensen-Shannon':<15} {'Earth Mover\\\\'s Dist':<15}\")\n",
    "            print(\"-\"*85)\n",
    "            \n",
    "            # Print data\n",
    "            for feature, metrics in sorted(result['numeric'].items()):\n",
    "                print(f\"{feature:<20} {metrics.get('ks_statistic', '-'):<15.6f} \"\n",
    "                      f\"{metrics.get('ks_pvalue', '-'):<15.6f} \"\n",
    "                      f\"{metrics.get('jensen_shannon', '-'):<15.6f} \"\n",
    "                      f\"{metrics.get('earth_movers_distance', '-'):<15.6f}\")\n",
    "        \n",
    "        # Print categorical features\n",
    "        if result['categorical']:\n",
    "            print(\"\\nCATEGORICAL FEATURES\")\n",
    "            print(\"-\"*100)\n",
    "            \n",
    "            # Print header\n",
    "            print(f\"{'Feature':<15} {'Chi² Statistic':<15} {'Chi² p-value':<15} {'G-test Statistic':<15} \"\n",
    "                  f\"{'G-test p-value':<15} {'Fisher p-value':<15} {'Jensen-Shannon':<15}\")\n",
    "            print(\"-\"*105)\n",
    "            \n",
    "            # Print data\n",
    "            for feature, metrics in sorted(result['categorical'].items()):\n",
    "                fisher_pval = metrics.get('fisher_pvalue', np.nan)\n",
    "                if isinstance(fisher_pval, (list, np.ndarray)) and len(fisher_pval) > 0:\n",
    "                    fisher_pval = fisher_pval[0]\n",
    "                elif fisher_pval is None:\n",
    "                    fisher_pval = np.nan\n",
    "                    \n",
    "                print(f\"{feature:<15} {metrics.get('chi2_statistic', np.nan):<15.6f} \"\n",
    "                      f\"{metrics.get('chi2_pvalue', np.nan):<15.6f} \"\n",
    "                      f\"{metrics.get('g_test_statistic', np.nan):<15.6f} \"\n",
    "                      f\"{metrics.get('g_test_pvalue', np.nan):<15.6f} \"\n",
    "                      f\"{fisher_pval:<15.6f} \"\n",
    "                      f\"{metrics.get('jensen_shannon', np.nan):<15.6f}\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "def print_results_summary(results):\n",
    "    \"\"\"\n",
    "    Print a summary of results across all files without tabulate.\n",
    "    \n",
    "    Args:\n",
    "        results: List of dictionaries with analysis results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"SUMMARY OF RESULTS\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Collect all numeric and categorical features across files\n",
    "    all_numeric = set()\n",
    "    all_categorical = set()\n",
    "    \n",
    "    for result in results:\n",
    "        if 'error' in result:\n",
    "            continue\n",
    "        all_numeric.update(result['numeric'].keys())\n",
    "        all_categorical.update(result['categorical'].keys())\n",
    "    \n",
    "    # Print header\n",
    "    print(f\"{'File':<20} {'Avg JS (Num)':<15} {'Avg KS (Num)':<15} {'Avg EMD (Num)':<15} \"\n",
    "          f\"{'Avg JS (Cat)':<15} {'Avg Chi² p-val':<15} {'Avg G-test p-val':<15}\")\n",
    "    print(\"-\"*110)\n",
    "    \n",
    "    # Print summary data for each file\n",
    "    for result in results:\n",
    "        if 'error' in result:\n",
    "            continue\n",
    "        \n",
    "        file_name = result['file']\n",
    "        \n",
    "        # Calculate average metrics for each file\n",
    "        num_js_values = [metrics.get('jensen_shannon', np.nan) for metrics in result['numeric'].values()]\n",
    "        num_js_avg = np.nanmean(num_js_values) if num_js_values else np.nan\n",
    "        \n",
    "        num_ks_values = [metrics.get('ks_statistic', np.nan) for metrics in result['numeric'].values()]\n",
    "        num_ks_avg = np.nanmean(num_ks_values) if num_ks_values else np.nan\n",
    "        \n",
    "        num_emd_values = [metrics.get('earth_movers_distance', np.nan) for metrics in result['numeric'].values()]\n",
    "        num_emd_avg = np.nanmean(num_emd_values) if num_emd_values else np.nan\n",
    "        \n",
    "        cat_js_values = [metrics.get('jensen_shannon', np.nan) for metrics in result['categorical'].values()]\n",
    "        cat_js_avg = np.nanmean(cat_js_values) if cat_js_values else np.nan\n",
    "        \n",
    "        cat_chi2_values = [metrics.get('chi2_pvalue', np.nan) for metrics in result['categorical'].values()]\n",
    "        cat_chi2_avg = np.nanmean(cat_chi2_values) if cat_chi2_values else np.nan\n",
    "        \n",
    "        cat_gtest_values = [metrics.get('g_test_pvalue', np.nan) for metrics in result['categorical'].values()]\n",
    "        cat_gtest_avg = np.nanmean(cat_gtest_values) if cat_gtest_values else np.nan\n",
    "        \n",
    "        print(f\"{file_name:<20} {num_js_avg:<15.6f} {num_ks_avg:<15.6f} {num_emd_avg:<15.6f} \"\n",
    "              f\"{cat_js_avg:<15.6f} {cat_chi2_avg:<15.6f} {cat_gtest_avg:<15.6f}\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "def run_analysis(csv_files=None, directory=None, target_feature='income', target_value='>50K', \n",
    "                 synthetic_feature='synthetic', plot=False, plot_dir='distribution_plots',\n",
    "                 detailed_output=True, summary_output=True):\n",
    "    \"\"\"\n",
    "    Main function to run the distribution analysis.\n",
    "    \n",
    "    Args:\n",
    "        csv_files: List of paths to CSV files (default: None)\n",
    "        directory: Directory containing CSV files (default: None)\n",
    "        target_feature: Column name for the target feature (default: 'income')\n",
    "        target_value: Value in target feature to filter for (default: '>50K')\n",
    "        synthetic_feature: Column name indicating if a record is synthetic (default: 'synthetic')\n",
    "        plot: Whether to generate distribution plots (default: False)\n",
    "        plot_dir: Directory to save plots to (default: 'distribution_plots')\n",
    "        detailed_output: Whether to print detailed results for each file (default: True)\n",
    "        summary_output: Whether to print a summary of results across files (default: True)\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries with analysis results\n",
    "    \"\"\"\n",
    "    # Get CSV files\n",
    "    files_to_analyze = []\n",
    "    \n",
    "    if csv_files:\n",
    "        files_to_analyze.extend(csv_files)\n",
    "    \n",
    "    if directory:\n",
    "        dir_files = [os.path.join(directory, f) for f in os.listdir(directory) \n",
    "                     if f.endswith('.csv')]\n",
    "        files_to_analyze.extend(dir_files)\n",
    "    \n",
    "    if not files_to_analyze:\n",
    "        # If no files specified, use current directory\n",
    "        files_to_analyze = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "        files_to_analyze = [os.path.join('.', f) for f in files_to_analyze]\n",
    "    \n",
    "    if not files_to_analyze:\n",
    "        print(\"No CSV files found.\")\n",
    "        return []\n",
    "    \n",
    "    results = analyze_distributions(\n",
    "        files_to_analyze, \n",
    "        target_feature=target_feature,\n",
    "        target_value=target_value,\n",
    "        synthetic_feature=synthetic_feature,\n",
    "        output_dir=plot_dir if plot else None, \n",
    "        plot=plot\n",
    "    )\n",
    "    \n",
    "    if detailed_output:\n",
    "        print_results_detailed(results)\n",
    "    \n",
    "    if summary_output and len(results) > 1:\n",
    "        print_results_summary(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# This code runs if this script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Analyze distributions of real vs synthetic data.')\n",
    "    parser.add_argument('--files', nargs='+', help='List of CSV files to analyze')\n",
    "    parser.add_argument('--dir', help='Directory containing CSV files to analyze')\n",
    "    parser.add_argument('--target-feature', default='income', \n",
    "                        help='Target feature column name (default: income)')\n",
    "    parser.add_argument('--target-value', default='>50K', \n",
    "                        help='Target value to filter for (default: >50K)')\n",
    "    parser.add_argument('--synthetic-feature', default='synthetic', \n",
    "                        help='Column indicating synthetic records (default: synthetic)')\n",
    "    parser.add_argument('--plot', action='store_true', help='Generate distribution plots')\n",
    "    parser.add_argument('--plot-dir', default='distribution_plots', \n",
    "                        help='Directory to save distribution plots')\n",
    "    parser.add_argument('--no-details', action='store_true', \n",
    "                        help='Skip printing detailed results')\n",
    "    parser.add_argument('--no-summary', action='store_true', \n",
    "                        help='Skip printing summary results')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    run_analysis(\n",
    "        csv_files=args.files,\n",
    "        directory=args.dir,\n",
    "        target_feature=args.target_feature,\n",
    "        target_value=args.target_value,\n",
    "        synthetic_feature=args.synthetic_feature,\n",
    "        plot=args.plot,\n",
    "        plot_dir=args.plot_dir,\n",
    "        detailed_output=not args.no_details,\n",
    "        summary_output=not args.no_summary\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a6cb2da",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_analysis() got an unexpected keyword argument 'detailed_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m target_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m target_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcsv_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles_to_analyze\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mincome\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetailed_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msummary_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: run_analysis() got an unexpected keyword argument 'detailed_output'"
     ]
    }
   ],
   "source": [
    "files_to_analyze = [\"OutputTrainingSets/augmented_trainVALIDATE1.csv\", \"OutputTrainingSets/augmented_trainVALIDATE2.csv\", \"OutputTrainingSets/augmented_trainVALIDATE3.csv\", \"OutputTrainingSets/augmented_trainVALIDATE4.csv\", \"OutputTrainingSets/augmented_trainVALIDATE5.csv\", \"OutputTrainingSets/augmented_trainVALIDATE6.csv\", \"OutputTrainingSets/augmented_trainVALIDATE7.csv\", \"OutputTrainingSets/augmented_trainVALIDATE8.csv\", \"OutputTrainingSets/augmented_trainVALIDATE9.csv\", \"OutputTrainingSets/augmented_trainVALIDATE10.csv\"]\n",
    "target_feature = 'income'\n",
    "target_value = '1'\n",
    "\n",
    "\n",
    "results = run_analysis(\n",
    "    csv_files=files_to_analyze,\n",
    "    target_feature='income',\n",
    "    target_value='1',synhetic_feature = 'synthetic'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77325cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dd6a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
