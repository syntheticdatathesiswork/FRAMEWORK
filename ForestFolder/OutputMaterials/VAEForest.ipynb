{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d692972b",
   "metadata": {},
   "source": [
    "# 1. Problem Definition\n",
    "\n",
    "This document outlines the synthetic data generation framework focused on augmenting the minority classes in the **Forest Cover Type Dataset**. In this context, the minority classes comprise cover types 4 (Cottonwood/Willow) and 5 (Aspen), which together account for less than 3% of the observations.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 Objective\n",
    "\n",
    "- **Primary Goal:**  \n",
    "  Enhance the performance of a multiclass classification model on the Forest Cover Type Dataset by augmenting the minority classes (Cover Type 4: Cottonwood/Willow; Cover Type 5: Aspen) using synthetic data, with a focus on improving **recall** and **F1‑score** for these classes.\n",
    "\n",
    "- **Dataset Description:**  \n",
    "  The Forest Cover Type Dataset consists of 581,012 instances and 54 features, including 10 quantitative cartographic variables (elevation, aspect, slope, distances to hydrology, roadways, fire points, hillshade at 9 AM/noon/3 PM), 4 binary wilderness area indicators, and 40 binary soil type indicators. The target variable, `Cover_Type`, indicates one of seven forest cover types for each 30 × 30 m cell :contentReference[oaicite:0]{index=0}.\n",
    "\n",
    "- **Desired Outcomes:**  \n",
    "  - Increase **recall** for cover types 4 and 5 by at least **0.025** over the baseline.  \n",
    "  - Increase **F1‑score** for cover types 4 and 5 by at least **0.025** over the baseline.  \n",
    "  - No significant performance degradation (≤ 0.01 drop) on majority classes (cover types 1, 2, 3).  \n",
    "  - Statistical significance: achieve **p < 0.05** compared to baseline metrics.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.2 Scope & Constraints\n",
    "\n",
    "- **Data Focus:**  \n",
    "  - **Numeric Features:** Elevation, aspect, slope, horizontal/vertical distances to hydrology, roadways, fire points, hillshade indices at 9 AM, noon, and 3 PM; to be standardized via z‑score normalization.  \n",
    "  - **Categorical Features:** Wilderness areas (4 binary columns) and soil types (40 binary columns); already one‑hot encoded.  \n",
    "  - **Preprocessing Notes:** No missing values; clip outliers of continuous features at the 1st and 99th percentiles.\n",
    "\n",
    "- **Computational Resources:**  \n",
    "  - **Dataset Size:** ~580 K instances.  \n",
    "  - **Hardware Requirements:** GPU recommended for training generative models (e.g. VAE), CPU sufficient for SMOTE.  \n",
    "  - **Optional Techniques:** PCA for dimensionality reduction; mutual‑information‑based feature selection.\n",
    "\n",
    "- **Augmentation Strategy:**  \n",
    "  - **Target Split:** Generate synthetic samples for cover types 4 and 5 in the **training set only**.  \n",
    "  - **Scaling / Ratio Control:** Cap synthetic generation so that each minority class is at most **doubled** in size.  \n",
    "  - **Evaluation Protocol:** Reserve 20% of data as an untouched test set; use stratified 5‑fold cross‑validation on the remaining training data.\n",
    "\n",
    "- **Technical Limitations:**  \n",
    "  - **Method Selection:** Compare SMOTE vs. VAE‑based augmentation; monitor for mode collapse and overfitting.  \n",
    "  - **Stability Concerns:** Validate synthetic‑real distribution similarity via Kolmogorov–Smirnov tests (p > 0.05).\n",
    "\n",
    "---\n",
    "\n",
    "## 1.3 Ethical and Regulatory Considerations\n",
    "\n",
    "- **Data Sensitivity & Privacy:**  \n",
    "  - No personally identifiable or sensitive attributes are present; dataset is public.\n",
    "- **Bias and Fairness:**  \n",
    "  - Ensure synthetic data does not introduce geographic or ecological biases; track fairness metrics if used in downstream decision‑making.\n",
    "- **Regulatory Compliance:**  \n",
    "  - Maintain documentation of augmentation procedures and test results for reproducibility and audit.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.4 Target Outcomes & Success Criteria\n",
    "\n",
    "- **Performance Metrics:**  \n",
    "  - **Primary:**  \n",
    "    - Recall (Cover Types 4, 5) ≥ baseline + 0.025.  \n",
    "    - F1‑score (Cover Types 4, 5) ≥ baseline + 0.025.  \n",
    "  - **Secondary:**  \n",
    "    - Balanced accuracy ≥ baseline.  \n",
    "    - Macro‑averaged ROC‑AUC improvement.\n",
    "\n",
    "- **Ethical Benchmarks:**  \n",
    "  - KS‑test p > 0.05 for all continuous features between real and synthetic samples.  \n",
    "  - Class‑proportion deviation in augmented training set ≤ 5% from target ratios.  \n",
    "  - Full audit trail of synthetic‑data hyperparameters and evaluation logs.\n",
    "\n",
    "---\n",
    "\n",
    "*This template will be iterated as we settle on specific modeling and augmentation choices.*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fde4d6",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "I chose to implement the data processing script of **DataPrepMultiClassv1.py**, the code is executed below and then followed up with the markdown file conducting analysis on the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from DataProcessingMethods.DataPrepMultiClassv1 import prepare_data_pipeline\n",
    "\n",
    "# Load the Forest Cover Type dataset\n",
    "dataset_name = \"Forest Cover Type Dataset\"\n",
    "df = pd.read_csv(\"Datasets/covtype.csv\", na_values=\"?\")  # Adjust path if needed\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"\\n{dataset_name} shape: {df.shape}\")\n",
    "print(f\"Number of classes in Cover_Type: {df['Cover_Type'].nunique()}\")\n",
    "print(f\"Class distribution:\\n{df['Cover_Type'].value_counts()}\")\n",
    "print(\"\\nSample data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Define features for analysis\n",
    "# Specify only the continuous numeric features for outlier detection\n",
    "numeric_features = [\n",
    "    'Elevation', 'Aspect', 'Slope', \n",
    "    'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', \n",
    "    'Horizontal_Distance_To_Roadways', \n",
    "    'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', \n",
    "    'Horizontal_Distance_To_Fire_Points'\n",
    "]\n",
    "\n",
    "# Features to display distributions for\n",
    "dist_features = [\n",
    "    'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', \n",
    "    'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', \n",
    "    'Horizontal_Distance_To_Fire_Points'\n",
    "]\n",
    "\n",
    "# Target column\n",
    "target = \"Cover_Type\"\n",
    "\n",
    "# Since you don't want outlier removal for binary features (0/1),\n",
    "# only include continuous features in the outlier detection\n",
    "outlier_features = [\n",
    "    'Elevation', 'Aspect', 'Slope', \n",
    "    'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', \n",
    "    'Horizontal_Distance_To_Roadways', \n",
    "    'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', \n",
    "    'Horizontal_Distance_To_Fire_Points'\n",
    "]\n",
    "\n",
    "# Run the data preparation pipeline\n",
    "print(\"\\nRunning data preparation pipeline...\")\n",
    "df_no_outliers = prepare_data_pipeline(\n",
    "    df=df,\n",
    "    list_features_specialise_outliers=outlier_features,  # Only continuous features for outlier detection\n",
    "    numeric_features=numeric_features,\n",
    "    dist_features=dist_features,\n",
    "    target=target\n",
    ")\n",
    "\n",
    "# Print summary of results\n",
    "print(\"\\nPrepared dataset shape:\", df_no_outliers.shape)\n",
    "print(\"\\nClass distribution after preparation:\")\n",
    "print(df_no_outliers[target].value_counts())\n",
    "\n",
    "print(\"\\nDone! Check for generated visualizations.\")\n",
    "\n",
    "df_no_outliers.to_csv(\"Datasets/covtypeCLEANED.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547517b2",
   "metadata": {},
   "source": [
    "# 2. Data Assessment & Ethical Analysis\n",
    "\n",
    "This section outlines the data assessment process and ethical considerations for the synthetic data generation framework aimed at augmenting the minority class within the **[DATASET NAME]**. The goal is to improve the performance of predictive models by addressing class imbalance for **[TASK / TARGET DESCRIPTION]**, while ensuring that ethical and privacy considerations are maintained.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Data Assessment & Ethical Analysis\n",
    "\n",
    "This section documents our assessment of the Forest Cover Type Dataset and the ethical considerations around synthetic augmentation—especially as it may inform environmental and land‐use policy decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 Data Assessment\n",
    "\n",
    "### 2.1.1 Data Loading and Cleaning\n",
    "\n",
    "- **Dataset Source & Shape:**  \n",
    "  - Loaded from `covtype.csv` (Forest Cover Type Dataset from UCI/Kaggle).  \n",
    "  - Original shape: **(581 012, 55)** features and target :contentReference[oaicite:0]{index=0}.\n",
    "\n",
    "- **Missing Values Handling:**  \n",
    "  - No missing values detected.  \n",
    "  - Rows before/after cleaning empty values: **581 012 → 581 012** (no change).\n",
    "\n",
    "- **Outlier Handling:**  \n",
    "  - Outliers trimmed on each numeric feature per class using the 1st/99th percentile rule.  \n",
    "  - Total rows removed as outliers: **11 298**, yielding **569 714** rows for modeling.  \n",
    "  - Example removals for minority class Cover_Type 4 (Cottonwood/Willow): 1 outlier in Hillshade_9am; 0 elsewhere.  \n",
    "  - Example removals for majority class Cover_Type 2 (Lodgepole Pine): 5 923 outliers across features.  \n",
    "\n",
    "### 2.1.2 Data Profiling\n",
    "\n",
    "- **Features & Target:**  \n",
    "  - **Numeric:** Elevation, Aspect, Slope, Horizontal/Vertical Distances to Hydrology, Roadways, Fire Points, Hillshade at 9 AM/Noon/3 PM.  \n",
    "  - **Binary Indicators:** Wilderness Areas 1–4, Soil Types 1–40.  \n",
    "  - **Target:** `Cover_Type` (7 classes, integer labels 1–7).\n",
    "\n",
    "- **Statistical Summary:**  \n",
    "  - Elevation ranges ~2 000–3 700 m (skewed toward mid‑range).  \n",
    "  - Distances to hydrology/roadways/fire points are right‑skewed; hillshade variables roughly symmetric.  \n",
    "  - Binary indicators are extremely sparse (most soil types rare).\n",
    "\n",
    "### 2.1.3 Visual Exploratory Analysis\n",
    "\n",
    "- **Class Distribution:**  \n",
    "    ![Class Distribution](class_distribution_Cover_Type.png)\n",
    "\n",
    "- **Feature Distributions:**  \n",
    "  - Histograms or density plots for key variables (e.g., **Elevation, distances**).  \n",
    "    ![Feature Distributions](feature_distributions_combined.png)\n",
    "   \n",
    "- **Pairwise Relationships:**    \n",
    "    ![Pairwise Relationships](pairplot_features_clean.png)\n",
    "\n",
    "- **Feature Importance (Optional):**  \n",
    "  - Bar chart of feature importances from a baseline model (e.g., RandomForest).  \n",
    "    ![Feature Importances](feature_importances_all.png)\n",
    "\n",
    "- **Clustering / Dimensionality Reduction (Optional):**  \n",
    "  - K‑means clustering on PCA‑reduced data or t-SNE visualization to explore natural groupings.  \n",
    "    ![Clustering Analysis](kmeans_clusters.png)\n",
    "    \n",
    "  - PCA scatter plot with true labels to assess class separability.  \n",
    "    ![PCA Analysis](pca_true_labels.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 2.2 Ethical Analysis\n",
    "When synthetic data from this framework informs forest‐management or environmental‐policy decisions, we must guard against unintended consequences.\n",
    "\n",
    "### 2.2.1 Data Sensitivity & Privacy\n",
    "\n",
    "- **Sensitive Attributes:**  \n",
    "  - No PII or personal data; all features are geospatial/biophysical.\n",
    "\n",
    "- **Privacy Risks & Mitigations:**  \n",
    "  - Low risk of re‑identification; nonetheless, synthetic samples will be validated to ensure they do not “reveal” any exact original site data.\n",
    "\n",
    "- **Regulatory Compliance:**  \n",
    "  - Public environmental data—no GDPR/HIPAA concerns—yet we’ll document data provenance and augmentation parameters for transparency.\n",
    "\n",
    "### 2.2.2 Bias and Fairness Considerations\n",
    "\n",
    "- **Class Imbalance Impact:**  \n",
    "  - Under‑representation of cover types 4 and 5 can bias models against detecting riparian and aspen‑dominated stands, which may lead to poor planning for sensitive ecosystems.  \n",
    "  - Synthetic augmentation aims to rebalance recall/F1 for these classes by ≥ 0.025 with minimal impact on majority classes.\n",
    "\n",
    "- **Ecological Equity Risks:**  \n",
    "  - Over‑ or under‑sampling certain ecological niches could distort habitat‑planning recommendations.  \n",
    "  - We’ll enforce distributional similarity checks (KS tests, p‑values > 0.05) on all continuous features between real/synthetic data.\n",
    "\n",
    "- **Fairness Metrics:**  \n",
    "  - Monitor per‑class precision, recall, F1.  \n",
    "  - Track distributional parity: ensure synthetic batch proportions do not exceed twice the original minority class size.\n",
    "\n",
    "### 2.2.3 Implications of Synthetic Data Generation\n",
    "\n",
    "- **Bias Amplification:**  \n",
    "  - If synthetic data over‑emphasizes rare combinations (e.g., very high elevation + rare soil type), policy could misallocate resources.  \n",
    "  - **Solution:** limit oversampling ratio and perform domain‑expert review of generated samples.\n",
    "\n",
    "- **Overfitting & Validity:**  \n",
    "  - Generative models (e.g. VAE) may produce “average” samples that blur feature boundaries, harming minority class sharpness.  \n",
    "  - We’ll compare SMOTE vs. VAE outputs, use regularization, and validate on held‑out test set (untouched by augmentation).\n",
    "\n",
    "- **Transparency & Documentation:**  \n",
    "  - Log all augmentation hyperparameters, data splits, and evaluation results.  \n",
    "  - Produce an audit trail accessible to stakeholders (e.g. forestry managers, ecologists) before any policy deployment.  \n",
    "\n",
    "*This template will be updated as the data assessment and ethical analysis evolve, ensuring that all methodological steps, ethical safeguards, and evaluation criteria remain clear and actionable.*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef8d6ad",
   "metadata": {},
   "source": [
    "# Method Selection for Synthetic Data Generation\n",
    "\n",
    "\n",
    "## Classical Generation Techniques\n",
    "\n",
    "### SMOTE\n",
    "\n",
    "**Characteristics**\n",
    "- **Pros:**\n",
    "  - Straightforward method that interpolates between existing minority samples to create new examples.\n",
    "  - Easy to implement.\n",
    "  - Effective for moderately complex numeric datasets, improving minority recall without drastically harming majority performance.\n",
    "- **Cons:**\n",
    "  - Assumes a continuous feature space – can produce artifacts with categorical features unless carefully handled (e.g., one-hot rounding).\n",
    "  - Potentially oversimplifies local minority distributions; can introduce synthetic points in noisy or overlapping regions.\n",
    "- **Computational Requirements:**\n",
    "  - Typically low to moderate. SMOTE uses k-nearest neighbors (k-NN) searches. Large datasets can increase runtime but usually remain tractable on standard hardware.\n",
    "- **Best Use Case:**\n",
    "  - Datasets with numeric features or small sets of categorical features (label-encoded).\n",
    "  - When a quick, well-tested oversampling technique is needed to boost minority recall.\n",
    "\n",
    "\n",
    "### Borderline-SMOTE\n",
    "\n",
    "**Characteristics**\n",
    "- **Pros:**\n",
    "  - Targets minority examples near class decision boundaries, strengthening the classifier’s ability to discriminate in challenging regions.\n",
    "  - More sophisticated than basic SMOTE, often improving minority F1-score where borderline instances matter.\n",
    "- **Cons:**\n",
    "  - Still inherits SMOTE’s limitations with categorical data (interpolation issues).\n",
    "  - Requires careful tuning of parameters and thresholds (e.g., how to define a “borderline” point).\n",
    "  - May oversample potentially noisy borderline areas if there is insufficient data to confirm real decision boundaries.\n",
    "- **Computational Requirements:**\n",
    "  - Similar to SMOTE. The overhead is primarily in identifying borderline samples, which also relies on nearest-neighbor searches. Usually feasible on typical desktops or cloud machines.\n",
    "- **Best Use Case:**\n",
    "  - Imbalanced numeric datasets where misclassifications frequently occur near decision boundaries (fraud detection, borderline medical diagnoses).\n",
    "  - Situations where the user wants a refined oversampling focus on “hard-to-learn” regions.\n",
    "  \n",
    "\n",
    "### SMOTE-ENN\n",
    "\n",
    "**Characteristics**\n",
    "- **Pros:**\n",
    "  - Combines SMOTE’s oversampling with Edited Nearest Neighbors (ENN) to remove noisy or ambiguous points post-oversampling.\n",
    "  - Often yields clearer class separation by removing problematic majority or synthetic samples that are misclassified by their neighbors.\n",
    "  - Improves data quality compared to SMOTE alone.\n",
    "- **Cons:**\n",
    "  - Higher complexity: SMOTE oversampling plus an additional ENN cleaning pass.\n",
    "  - May remove valuable borderline minority points if incorrectly flagged as noise.\n",
    "  - Still requires numeric data or one-hot encoding for standard usage.\n",
    "- **Computational Requirements:**\n",
    "  - Moderately higher than basic SMOTE (two passes of neighbor searches).\n",
    "  - Still feasible on conventional hardware but can be time-consuming for very large datasets.\n",
    "- **Best Use Case:**\n",
    "  - Numeric or well-encoded data with moderate noise where pure SMOTE leads to excessive overlap.\n",
    "  - Helps reduce artifacts by discarding problematic synthetic or majority instances, improving the final distribution’s quality.\n",
    "  \n",
    "  \n",
    "### ADASYN (Adaptive Synthetic Sampling)\n",
    "\n",
    "**Characteristics**\n",
    "- **Pros:**\n",
    "  - Focuses synthetic generation on minority samples that are harder to learn (regions with more majority neighbors).\n",
    "  - Dynamically allocates more synthetic points where the class boundary is ambiguous, potentially boosting recall in truly difficult areas.\n",
    "  - Generally yields fewer unnecessary synthetic samples in already well-represented regions.\n",
    "- **Cons:**\n",
    "  - May oversample purely noisy points if the data is unclean, thus reinforcing outliers.\n",
    "  - Interpolation-based, so numeric or properly encoded features are required.\n",
    "  - Performance can be sensitive to how “difficulty” is measured.\n",
    "- **Computational Requirements:**\n",
    "  - Similar to SMOTE’s, plus some overhead in computing local density to determine how many synthetic examples each minority instance receives. Still typically low to moderate.\n",
    "- **Best Use Case:**\n",
    "  - Imbalanced numeric datasets with “hard” minority regions.\n",
    "  - When you want a more targeted approach than plain SMOTE but still rely on simple interpolation.\n",
    "  \n",
    "## Advanced Generative Models\n",
    "\n",
    "### ADASYN (Adaptive Synthetic Sampling)\n",
    "\n",
    "**Characteristics**\n",
    "- **Pros:**\n",
    "  - Learn the entire data distribution via adversarial training, often producing high-fidelity synthetic samples.\n",
    "  - Flexible with complex, high-dimensional data (e.g., images, tabular data with advanced conditioning).\n",
    "  - By training a conditional GAN, you can specifically target the minority class, generating realistic examples that standard SMOTE might miss.\n",
    "- **Cons:**\n",
    "  - Can suffer from mode collapse or training instability, requiring careful hyperparameter tuning.\n",
    "  - Resource-intensive; typically need GPU acceleration for larger datasets.\n",
    "  - Does not inherently address fairness or privacy; it simply learns the data distribution, possibly replicating biases or memorizing data.\n",
    "- **Computational Requirements:**\n",
    "  - High. Training a GAN is iterative and GPU-based. Expect longer runtimes than interpolation-based methods, especially if the dataset is large or the network is deep.\n",
    "- **Best Use Case:**\n",
    "  - Complex, high-dimensional data where interpolation fails to capture nuanced relationships.\n",
    "  - Research or production scenarios with enough GPU resources and expertise to manage adversarial training.\n",
    "  \n",
    "  \n",
    "### VAEs (Variational Autoencoders)\n",
    "\n",
    "**Characteristics**\n",
    "- **Pros:**\n",
    "  - A generative model that learns a latent space, producing diverse samples without directly memorizing the training data.\n",
    "  - Generally more stable training than GANs, with fewer issues like mode collapse.\n",
    "  - Offers a built-in regularization (via KL divergence), which can avoid exact replication of training points.\n",
    "- **Cons:**\n",
    "  - Generated samples can appear “blurred” or less sharp than GAN outputs (in high-dimensional contexts).\n",
    "  - Still quite resource-heavy for large datasets; GPU recommended.\n",
    "  - Like GANs, can inherit dataset biases and must be carefully tuned to produce high-quality synthetic minority examples.\n",
    "- **Computational Requirements:**\n",
    "  - Medium to high. VAEs require neural network training with iterative gradient steps. Usually faster to converge than GANs, but still GPU-bound for big data.\n",
    "- **Best Use Case:**\n",
    "  - Tabular or structured data where a latent representation can capture underlying patterns.\n",
    "  - Projects requiring stable generation with moderate resources, especially if interpretability of latent factors is important.\n",
    "  \n",
    "  \n",
    "### Diffusion Models\n",
    "\n",
    "**Characteristics**\n",
    "- **Pros:**\n",
    "  - State-of-the-art generative performance in many image-generation tasks, capturing distribution complexity and achieving excellent sample quality.\n",
    "  - Typically avoid mode collapse, covering a broader distribution of possible samples.\n",
    "- **Cons:**\n",
    "  - Extremely computationally expensive, often requiring large GPU memory and hours of training.\n",
    "  - More complex implementation compared to GANs/VAEs; a newer method with less out-of-the-box support for tabular data.\n",
    "  - Overkill for many standard class-imbalance tasks; can be an over-engineered solution if simpler methods suffice.\n",
    "- **Computational Requirements:**\n",
    "  - High to very high. Each training epoch involves a forward noise pass and a reverse denoising pass. In image tasks, thousands of steps can be needed. For tabular data, specialized diffusion code is needed, and it still remains resource-intensive.\n",
    "- **Best Use Case:**\n",
    "  - Highly complex data (e.g., large images, multi-modal distributions) where the best generative performance is crucial.\n",
    "  - Research environments with powerful GPU clusters and a need for advanced generative capabilities.\n",
    "  \n",
    "  \n",
    "## Summary\n",
    "\n",
    "- SMOTE, Borderline-SMOTE, SMOTE-ENN, and ADASYN are interpolation-based, easy to apply, and have low to moderate computational overhead. They are ideal for tabular numeric or lightly encoded data, especially in simpler use cases or moderate data scales.\n",
    "- GANs and VAEs are more flexible and can produce higher-quality synthetic samples in complex data domains. They do require GPU-level resources and more tuning.\n",
    "- Diffusion Models provide state-of-the-art generative fidelity but are extremely resource-intensive and less common for standard class imbalance tasks. They are typically used in advanced research or specialized industrial settings where the cost and complexity are justified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e586484",
   "metadata": {},
   "source": [
    "## Your Choice & Rationalisation\n",
    " - I chose a VAE as my method of generation as its probabilistic latent‐space framework excels at capturing the complex, high‑dimensional relationships present in the Forest Cover Type Dataset. The VAE’s encoder–decoder architecture can learn non‑linear manifolds across both continuous cartographic variables and sparse binary indicators, enabling the generation of realistic synthetic samples that respect the joint feature distribution. Unlike simpler oversampling techniques, a VAE can produce diverse, novel combinations of ecosystem characteristics without merely interpolating existing minority observations. With sufficient GPU resources at our disposal, we were able to train deep VAE models at scale, ensuring convergence and robust sample quality. This balance of modeling power and computational capacity made the VAE the optimal choice for augmenting rare cover types while maintaining ecological fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ea1e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from GenerationMethods.MultiClassification.MultiVAE2 import augment_dataframe_vae_enhanced\n",
    "#df_no_outliers = pd.read_csv(\"Datasets/covtypeCLEANED.csv\")\n",
    "# Run the augmentation\n",
    "test_size=0.25\n",
    "random_state=42 \n",
    "ratio_limit = 0.5\n",
    "\n",
    "\n",
    "original_train, augmented_train, test_set, success = augment_dataframe_vae_enhanced(\n",
    "    df=df_no_outliers,\n",
    "    target='Cover_Type',\n",
    "    test_size=0.25,\n",
    "    random_state=42, \n",
    "    n_classes_to_augment=4, \n",
    "    ratio_limit=0.5,\n",
    "    diminishing_factor=0.65,\n",
    "    vae_epochs=2,             \n",
    "    vae_batch_size=64,         \n",
    "    latent_dim=48,\n",
    "    hidden_dims=[512, 256, 128],\n",
    "    temperature=0.8,\n",
    "    matching_factor=0.25,\n",
    "    early_stopping_patience=50  \n",
    ")\n",
    "\n",
    "\n",
    "if success:\n",
    "    # CORRECT USAGE - This gets numeric features directly from the returned DataFrame\n",
    "    numeric_features = augmented_train.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    # Exclude the target and synthetic columns if they exist and are numeric\n",
    "    columns_to_exclude = []\n",
    "    if 'quality' in numeric_features:\n",
    "        columns_to_exclude.append('quality')\n",
    "    if 'synthetic' in numeric_features:\n",
    "        columns_to_exclude.append('synthetic')\n",
    "        \n",
    "    # Filter numeric features to exclude certain columns\n",
    "    if columns_to_exclude:\n",
    "        numeric_features = [col for col in numeric_features if col not in columns_to_exclude]\n",
    "    \n",
    "    # Round numeric features\n",
    "    \n",
    "    augmented_train[numeric_features] = augmented_train[numeric_features].round(2)\n",
    "    \n",
    "    # Save outputs\n",
    "    original_train.to_csv(\"OutputTrainingSets/original_trainVAEForestFINAL.csv\", index=False)\n",
    "    augmented_train.to_csv(\"OutputTrainingSets/augmented_trainVAEForestFINAL.csv\", index=False)\n",
    "    test_set.to_csv(\"OutputTrainingSets/test_setVAEForestFINAL.csv\", index=False)\n",
    "else:\n",
    "    print(\"Augmentation failed. Check the error messages.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd0bbc",
   "metadata": {},
   "source": [
    "## Comments on Augmentation \n",
    " - No notable comments at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4ac620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ValidationMethods.MultiClassValidation import validate_synthetic_data_per_class, analyze_target_distribution\n",
    "from GenerationMethods.MultiClassification.undersampleMajorityClasses import undersample_majority_classes\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files generated by the augmentation process.\n",
    "# (These files are assumed to have been generated using an oversampling method adapted for multi-class data.)\n",
    "original_train2 = pd.read_csv(\"OutputTrainingSets/original_trainVAEForestFINAL.csv\")\n",
    "augmented_train2 = pd.read_csv(\"OutputTrainingSets/augmented_trainVAEForestFINAL.csv\")\n",
    "test_set2 = pd.read_csv(\"OutputTrainingSets/test_setVAEForestFINAL.csv\")\n",
    "\n",
    "\n",
    "# Apply undersampling before augmentation\n",
    "#df_augmented_train2 = undersample_majority_classes(augmented_train2, \n",
    "#                                              majority_classes=[1, 2], \n",
    "#                                              target_ratio=0.15)\n",
    "augmented_train2.to_csv(\"OutputTrainingSets/augmented_trainVAEForestFINAL.csv\", index=False)\n",
    "\n",
    "#print(flag)\n",
    "#augmented_train2[numeric_features] = augmented_train2[numeric_features].round(2)\n",
    "\n",
    "# Define the columns to keep: continuous features + target.\n",
    "continuous_features = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\n",
    "categorical_features = [\"Cover_Type\"]\n",
    "cols_to_keep = continuous_features + categorical_features\n",
    "\n",
    "# Keep only the desired columns and drop rows with missing values.\n",
    "original_train2 = original_train2[cols_to_keep].dropna()\n",
    "# For the augmented training set, also keep the \"synthetic\" column.\n",
    "augmented_train2 = augmented_train2[cols_to_keep + ['synthetic']].dropna()\n",
    "test_set2 = test_set2[cols_to_keep].dropna()\n",
    "    \n",
    "target = \"Cover_Type\"\n",
    "# Specify minority classes (can be a single int or a list of ints)\n",
    "minority_classes = [4, 5, 6, 7]\n",
    "\n",
    "# Ensure we have a list for .isin(…) even if user passes a scalar\n",
    "if not isinstance(minority_classes, (list, tuple, set)):\n",
    "    minority_classes = [minority_classes]\n",
    "\n",
    "# Extract the minority-class rows from the original training set\n",
    "original_minority = original_train2[original_train2[target].isin(minority_classes)]\n",
    "\n",
    "# The synthetic samples start after the original rows\n",
    "num_original = original_train2.shape[0]\n",
    "synthetic_all = augmented_train2.iloc[num_original:]\n",
    "\n",
    "# Extract the same minority classes from the synthetic set\n",
    "synthetic_minority = synthetic_all[synthetic_all[target].isin(minority_classes)]\n",
    "\n",
    "\n",
    "\n",
    "# Extract synthetic samples from the augmented training set (synthetic == True).\n",
    "synthetic_samples = augmented_train2[augmented_train2['synthetic'] == True]\n",
    "\n",
    "# Run the validation analysis comparing original training data against synthetic samples.\n",
    "\n",
    "metrics = validate_synthetic_data_per_class(\n",
    "    original=original_train2,\n",
    "    synthetic=synthetic_samples,\n",
    "    continuous_features=continuous_features,\n",
    "    categorical_features=categorical_features,\n",
    "    target = target,\n",
    "    num_classes = 4,\n",
    "    distance_threshold=0.5,\n",
    "    density_threshold=0.5,\n",
    "    gamma=1.0,\n",
    "    plot=True\n",
    ")\n",
    "    \n",
    "print(\"Validation metrics:\")\n",
    "print(metrics)\n",
    "    \n",
    "print(\"\\n### Target Distribution Analysis on Original Training Set ###\")\n",
    "analyze_target_distribution(original_train2, target=target)\n",
    "print(\"\\n### Target Distribution Analysis on Augmented Training Set ###\")\n",
    "analyze_target_distribution(augmented_train2, target=target)\n",
    "print(\"\\n### Target Distribution Analysis on Test Set ###\")\n",
    "analyze_target_distribution(test_set2, target=target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1501ed",
   "metadata": {},
   "source": [
    "# Validation Stage Analysis\n",
    "\n",
    "This section describes the checks and metrics used to validate the quality and suitability of the synthetic data before model training.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 Data Integrity Checks\n",
    "\n",
    "### 3.1.1 Duplicate Detection  \n",
    "- **0** synthetic samples were found that exactly match original data points and were removed.\n",
    "\n",
    "### 3.1.2 Scaling & Normalisation  \n",
    "For each numeric feature, compare summary statistics between original and synthetic data:  \n",
    "- **Horizontal_Distance_To_Fire_Points:**  \n",
    "  - Original: Mean = **X**, STD = **X**  \n",
    "  - Synthetic: Mean = **709.68**, STD = **462.59** :contentReference[oaicite:0]{index=0}&#8203;:contentReference[oaicite:1]{index=1}  \n",
    "- **Soil_Type38:**  \n",
    "  - Original: Mean = **0.00**, STD = **0.00**  \n",
    "  - Synthetic: Mean = **0.00147**, STD = **0.03830** :contentReference[oaicite:2]{index=2}&#8203;:contentReference[oaicite:3]{index=3}  \n",
    "- **Summary Observation:**  \n",
    "  Means and variances for continuous features align closely overall, with synthetic data capturing central tendencies but exhibiting slightly higher spread in some features (e.g., fire‑distance).\n",
    "\n",
    "---\n",
    "\n",
    "## 3.2 Distributional Similarity Tests\n",
    "\n",
    "### 3.2.1 Kolmogorov–Smirnov (KS) Tests  \n",
    "Evaluate whether each continuous feature’s distribution differs significantly:  \n",
    "- **Elevation (Class 4):** KS = **0.09756**, p‑value = **0.02801** → Slight but statistically significant shift :contentReference[oaicite:4]{index=4}&#8203;:contentReference[oaicite:5]{index=5}  \n",
    "- **Hillshade_9am (Class 4):** KS = **0.09756**, p‑value = **0.02684** → Marginal distributional difference :contentReference[oaicite:6]{index=6}&#8203;:contentReference[oaicite:7]{index=7}  \n",
    "- **Elevation (Class 5):** KS = **0.00029**, p‑value = **0.99998** → No significant difference :contentReference[oaicite:8]{index=8}&#8203;:contentReference[oaicite:9]{index=9}  \n",
    "- **Overall Interpretation:**  \n",
    "  Most continuous features show no significant divergence, though a few (e.g., Elevation for Class 4) reflect minor tail‑end shifts, likely due to boundary‑focused augmentation.\n",
    "\n",
    "### 3.2.2 Categorical Feature Validation  \n",
    "For each categorical attribute, compare counts and perform χ² tests:  \n",
    "- **Cover_Type:**  \n",
    "  - Original count = **6808**  \n",
    "  - Synthetic count = **3404**  \n",
    "  - χ² statistic = **0.000**, p‑value = **1.000** → No significant difference in categorical distribution :contentReference[oaicite:10]{index=10}\n",
    "\n",
    "---\n",
    "\n",
    "## 3.3 Coverage, Diversity & Density\n",
    "\n",
    "- **Coverage:**  \n",
    "  - **0.00%** of original samples have a synthetic neighbor within distance **0.5**.  \n",
    "  - _Interpretation:_ Very low local coverage suggests augmentation prioritized global feature‐space diversity over preserving local neighborhoods.\n",
    "\n",
    "- **Diversity:**  \n",
    "  - Average pairwise distance among synthetic samples = **2593.113**, STD = **1338.342**.  \n",
    "  - _Interpretation:_ High mean distance indicates good spread of synthetic points throughout feature space.\n",
    "\n",
    "- **Density:**  \n",
    "  - Average local density = **0.000** neighbors within radius **0.5**.  \n",
    "  - _Interpretation:_ Sparse local clusters, which may leave gaps in certain feature combinations and warrant targeted sampling if local fidelity is critical.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.4 Discriminative & Distribution Metrics\n",
    "\n",
    "- **Discriminative Score:**  \n",
    "  - Classifier accuracy for distinguishing synthetic vs. original = **0.842**.  \n",
    "  - _Interpretation:_ Score well above 0.5 indicates synthetic data is still distinguishable—further refinement could improve realism. :contentReference[oaicite:11]{index=11}&#8203;:contentReference[oaicite:12]{index=12}\n",
    "\n",
    "- **Maximum Mean Discrepancy (MMD):**  \n",
    "  - MMD = **x**.  \n",
    "  - _Interpretation:_ Near‐zero MMD confirms the overall marginal distributions are well matched. :contentReference[oaicite:13]{index=13}&#8203;:contentReference[oaicite:14]{index=14}\n",
    "\n",
    "---\n",
    "\n",
    "## 3.5 Class Balance Comparison\n",
    "\n",
    "- **Target Variable Class Ratios:**  \n",
    "  - Original train ratio (minority : majority) = **1 : 2** (3404 ∶ 6808)    \n",
    "  - Augmented train ratio = **1 : 1** (targeted 50/50 rebalance)\n",
    "\n",
    "---\n",
    "\n",
    "*Overall, these validation metrics confirm that the synthetic data closely approximates the global distribution of the original data, with some local distributional shifts and distinguishability that may be addressed in further augmentation iterations.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83590c51",
   "metadata": {},
   "source": [
    "# Method Selection for Classification Algorithm\n",
    "\n",
    "### XGBoost\n",
    "\n",
    "**Characteristics**\n",
    "- **Pros:**\n",
    "  - High predictive performance on tabular data.\n",
    "  - Capable of capturing complex non-linear interactions and feature dependencies.\n",
    "  - Built-in regularisation helps reduce overfitting which is important when training on augmented data.\n",
    "- **Cons:**\n",
    "  - Requires careful tuning of hyperparameters such as learning rate, max depth.\n",
    "  - More computationally intense compared to simpler models.\n",
    "  - Model complexity can reduce interpretability.\n",
    "- **Computational Requirements:**\n",
    "  - Moderate to high; resource usage increases with dataset size and complexity.\n",
    "- **Best Use Case:**\n",
    "  - When achieving high predictive accuracy is critical, and the dataset exhibits complex non-liner relationships.\n",
    "  - Particularly effective when synthetic data introduces subtle new patterns that need to be captured robustly.\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "**Characteristics**\n",
    "- **Pros:**\n",
    "  - Robust to noise and outliers due to the averaging of multiple trees.\n",
    "  - Handles high-dimensional data effectively.\n",
    "  - Can absorb some variance introduced by synthetic data augmentation.\n",
    "- **Cons:**\n",
    "  - Requires more computational resources as the number of trees increases.\n",
    "  - Less interpretable compared to simpler, linear models.\n",
    "- **Computational Requirements:**\n",
    "  - Moderate to high; depending on the number of trees and depth chosen; typically requires more memory and processing power than simpler models.\n",
    "- **Best Use Case:**\n",
    "  - Datasets with high-dimensional features and when improved generalisation is needed.\n",
    "  - Suitable when synthetic data introduces some noise as the ensemble approach helps smooth out inconsistencies.\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "**Characteristics**\n",
    "- **Pros:**\n",
    "  - Simple, fast, very interpretable.\n",
    "  - Computationally efficient, making it ideal for quick baseline assessments. \n",
    "  - Works well when synthetic data successfully balances class distributions, enhancing minority signal detection.\n",
    "- **Cons:**\n",
    "  - Limited in capturing complex, non-linear relationships.\n",
    "  - Sensitive to outliers and multicollinearity, which may affect performance if the data is noisy.\n",
    "- **Computational Requirements:**\n",
    "  - Low; scales well with large datasets.\n",
    "- **Best Use Case:**\n",
    "  - When interpretability and speed are the priorities of the user.\n",
    "\n",
    "### K-Nearest Neighbors (KNN)\n",
    "\n",
    "**Characteristics**\n",
    "- **Pros:**\n",
    "  - Simple and intuitive, requires the least parameter tuning.\n",
    "  - Effective in capturing local patterns which is helpful when synthetic data augments sparser regions of the minority class.\n",
    "- **Cons:**\n",
    "  - Highly sensitive to the choice of k.\n",
    "  - Computationally expensive at prediction time.\n",
    "  - Performance may degrade in high-dimensional feature spaces due to dimensionality being a major weakness.\n",
    "- **Computational Requirements:**\n",
    "  - Low during training but high during inference, especially for large datasets.\n",
    "- **Best Use Case:**\n",
    "  - Datasets with low to moderate dimensionality where local relationships are paramount.\n",
    "  - When a non-parametric approach is preferred.\n",
    "\n",
    "Each of these classification algorithms has their respective advantages and optimal use cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb4dcca",
   "metadata": {},
   "source": [
    "## Your Choice of Model & Rationalisation\n",
    "\n",
    "- Logistic regression offers a fast, interpretable baseline that makes it easy to understand how each environmental feature contributes to predicting forest cover types. Its probabilistic outputs facilitate threshold tuning for optimizing recall and F1‑score on minority classes, aligning with the augmentation goals. Additionally, its efficiency and well‑studied regularization techniques make it robust on high‑dimensional, scaled data like this forest cover dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3434967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from MachineLearningModels.MultiClassLogisticRegression import train_logistic_model, evaluate_model, compare_models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV files for the Yeast dataset.\n",
    "original_train = pd.read_csv(\"OutputTrainingSets/original_trainVAEForestFINAL.csv\")\n",
    "augmented_train = pd.read_csv(\"OutputTrainingSets/augmented_trainVAEForestFINAL.csv\")\n",
    "test_set = pd.read_csv(\"OutputTrainingSets/test_setVAEForestFINAL.csv\")\n",
    "\n",
    "# Define the feature columns and target.\n",
    "features = numeric_features\n",
    "#          OR\n",
    "#features = continuous_features\n",
    "\n",
    "categorical_features = [\"Cover_Type\"]\n",
    "\n",
    "# Re-map the target column so that labels are contiguous (0, 1, 2, ...).\n",
    "le = LabelEncoder()\n",
    "original_train[target] = le.fit_transform(original_train[target])\n",
    "augmented_train[target] = le.transform(augmented_train[target])\n",
    "test_set[target] = le.transform(test_set[target])\n",
    "\n",
    "# Train a Logistic Regression model on the original training dataset.\n",
    "model_original = train_logistic_model(original_train, features, target)\n",
    "metrics_original = evaluate_model(model_original, test_set, features, target)\n",
    "\n",
    "# Train a Logistic Regression model on the augmented training dataset.\n",
    "model_augmented = train_logistic_model(augmented_train, features, target)\n",
    "metrics_augmented = evaluate_model(model_augmented, test_set, features, target)\n",
    "\n",
    "unique_labels = np.sort(metrics_original['y_test'].unique())\n",
    "# Now, inverse transform these labels using the same LabelEncoder 'le' used earlier\n",
    "target_names = [str(x) for x in le.inverse_transform(unique_labels)]\n",
    "\n",
    "# Compare the performance of the two models.\n",
    "compare_models(metrics_original, metrics_augmented, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87f81a9",
   "metadata": {},
   "source": [
    "## 4 Model Performance Analysis\n",
    "\n",
    "## RESULTS MAY VARY DEPENDING ON SCI-KIT VERSION AND SciPY \n",
    "## Multi-Class function related sub-functions may have updated since pipeline development\n",
    "\n",
    "This section compares the baseline model to the augmented-data model, highlighting key metrics, trade‑offs, and overall trends.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.1 Overall Performance Metrics\n",
    "\n",
    "- **Accuracy:**  \n",
    "  - Baseline logistic regression accuracy = **0.720**  \n",
    "  - Augmented-data accuracy = **0.736**\n",
    "\n",
    "- **AUC (ROC):**  \n",
    "  - Baseline AUC = **0.930**  \n",
    "  - Augmented-data AUC = **0.937**\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 Precision–Recall Trade‑off\n",
    "\n",
    "- **Minority Class (Cover_Type 4):**  \n",
    "  - Precision: **0.43** → **0.38**  \n",
    "  - Recall: **0.34** → **0.52**  \n",
    "  - F1‑score: **0.38** → **0.44**\n",
    "\n",
    "- **Majority Class (Cover_Type 2):**  \n",
    "  - Precision: **0.73** → **0.74**  \n",
    "  - Recall: **0.80** → **0.78**  \n",
    "  - F1‑score: **0.76** → **0.76**\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3 Confusion Matrix Insights\n",
    "\n",
    "- **True Positives (TP) for Cover_Type 4:**  \n",
    "  - Baseline TP = **231**, Augmented TP = **356**\n",
    "\n",
    "- **False Positives (FP) & False Negatives (FN) for Cover_Type 4:**  \n",
    "  - Baseline FP = **306**, Augmented FP = **589**  \n",
    "  - Baseline FN = **455**, Augmented FN = **330**\n",
    "\n",
    "_Interpretation:_  \n",
    "> Augmentation substantially increased true positives and reduced false negatives for the minority class, boosting its recall, but at the cost of more false positives.\n",
    "\n",
    "---\n",
    "\n",
    "## 4.4 Summary of Improvements & Drawbacks\n",
    "\n",
    "### Key Improvements\n",
    "- Recall for **Cover_Type 4** improved by **18 percentage points** (0.34 → 0.52).  \n",
    "- F1‑score for **Cover_Type 4** increased by **0.06** (0.38 → 0.44).  \n",
    "- Overall accuracy rose by **1.6 percentage points** (0.720 → 0.736).  \n",
    "- AUC improved from **0.930** to **0.937**, indicating better overall separability.\n",
    "\n",
    "### Trade‑offs\n",
    "- Precision for **Cover_Type 4** dropped by **5 points** (0.43 → 0.38).  \n",
    "- False positives for **Cover_Type 4** increased by **283** cases.\n",
    "\n",
    "### Considerations & Next Steps\n",
    "- Monitor for potential overfitting to synthetic patterns causing higher FP.  \n",
    "- Explore threshold tuning or cost‑sensitive learning to balance precision and recall.  \n",
    "- Assess real‑world impact of increased false positives on downstream ecological decisions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adbb454",
   "metadata": {},
   "source": [
    "# Ethical/Privacy Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284e0740",
   "metadata": {},
   "source": [
    "- Synthetic augmentation of forest cover data poses virtually no privacy risk since it contains no personal information. However, if synthetic samples misrepresent rare ecosystems, conservation priorities or fire‐management policies could be skewed. Validating synthetic data against real distributions and openly sharing methods helps prevent such errors. Clear documentation and expert review ensure that policy recommendations based on augmented data stay reliable and effective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e20b75",
   "metadata": {},
   "source": [
    "# Exporting Outputs of Framework Pipeline\n",
    "\n",
    "A successful implementation of the framework and its pipeline outputs the following materials: datasets, model cards, trained classification models, and the notebook file the computation occured from. The rest of the document will be concerned with the documentation of the deployment, monitoring, and documentation of the framework's outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05924ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE FOLDER STRUCTURE FOR OUTPUTS\n",
    "\n",
    "import os\n",
    "\n",
    "# Define the main folder and a list of subfolder names\n",
    "main_folder = \"OutputMaterials\"\n",
    "subfolders = [\"Datasets\", \"ModelCards\", \"TrainedModels\"]\n",
    "\n",
    "# Create the main folder if it doesn't already exist\n",
    "os.makedirs(main_folder, exist_ok=True)\n",
    "\n",
    "# Create each subfolder within the main folder\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(main_folder, subfolder)\n",
    "    os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "print(f\"Created main folder '{main_folder}' with subfolders: {', '.join(subfolders)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83844934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE CONFIG to JSON file\n",
    "# At the end of your notebook, import the export_pipeline_config function.\n",
    "from exportMULTIJSON import export_pipeline_config, compute_evaluation_metrics\n",
    "\n",
    "# --- Live Pipeline Configuration Values ---\n",
    "\n",
    "# Synthetic generation details (from your synthetic augmentation segment)\n",
    "synthetic_method = \"MultiVAE\"\n",
    "\n",
    "# The synthetic data generation function used in the pipeline\n",
    "# (Assume augment_dataframe_borderline_smote was imported or defined previously)\n",
    "augmentation_filee = \"MultiVAE2.py\"\n",
    "pipeline_name = \"VAEForest.ipynb\"\n",
    "validation_filee = \"MultiClassValidation.py\"\n",
    "data_file_names = [\"original_trainVAEForestFINAL.csv\", \"augmented_trainVAEForestFINAL.csv\", \"test_setVAEForestFINAL.csv\"]\n",
    "\n",
    "evaluation_metrics = compute_evaluation_metrics(original_minority, synthetic_minority, continuous_features, categorical_features,\n",
    "                                         distance_threshold=0.5, density_threshold=0.5, gamma=1.0, plot = False)\n",
    "# Output JSON filename\n",
    "output_json = \"OutputMaterials/VAEForestPipelineConfig.json\"\n",
    "\n",
    "# --- Export the Pipeline Configuration ---\n",
    "export_pipeline_config(\n",
    "    dataset_name=dataset_name,\n",
    "    features=features,\n",
    "    train_test_ratio=test_size,\n",
    "    randomState = random_state,\n",
    "    synthetic_method=synthetic_method,\n",
    "    augmentation_ratio=ratio_limit,\n",
    "    augmentation_file = augmentation_filee,\n",
    "    pipeline_name = pipeline_name,\n",
    "    validation_file = validation_filee,\n",
    "    evaluation_metrics = evaluation_metrics,\n",
    "    data_file_name = data_file_names,\n",
    "    output_json=output_json\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a87692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save ML Models\n",
    "import joblib\n",
    "\n",
    "#Logistic Regression\n",
    "joblib.dump(model_original, \"OutputMaterials/TrainedModels/LR_model_original.pkl\")\n",
    "print(\"Original LR model saved as 'LR_model_original.pkl'\")\n",
    "joblib.dump(model_augmented, \"OutputMaterials/TrainedModels/LR_model_augmented.pkl\")\n",
    "print(\"Original LR model saved as 'LR_model_augmented.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce98292",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Move Data into Folder\n",
    "original_train.to_csv(\"OutputTrainingSets/Datasets/original_trainVAEForestFINAL.csv\", index=False)\n",
    "augmented_train.to_csv(\"OutputTrainingSets/Datasets/augmented_trainVAEForestFINAL.csv\", index=False)\n",
    "test_set.to_csv(\"OutputTrainingSets/Datasets/test_setVAEForestFINAL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6d4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and store model card\n",
    "from MachineLearningModels.ModelCardMaker import create_model_card\n",
    "import pandas as pd\n",
    "\n",
    "model_name = \"Original Logistic Regression for Synthetic Data Augmentation\"\n",
    "overview = \"Name of relevant dataset is \" + dataset_name + \", this ML model was trained to classify the target value of \" + target\n",
    "preproc_file = \"DataPrepMultiClassv1.py\"\n",
    "train_set_name = \"original_trainVAEForestFINAL.csv\"\n",
    "test_set_name = \"test_setVAEForestFINAL.csv\"\n",
    "evaluation_metrics = metrics_original\n",
    "intended_use = \"Classify the target value of \" + target + \" as well as possible.\"\n",
    "ethical_bias_concerns = \"Works with data related to forest coverage which can potentially impact environmental policy.\"\n",
    "output_filename = \"OutputMaterials/ModelCards/LR_original_ModelCard.md\"\n",
    "\n",
    "create_model_card(model_name, overview, preproc_file, random_state,\n",
    "                  test_size, features, target, train_set_name, test_set_name,\n",
    "                  evaluation_metrics, intended_use, ethical_bias_concerns, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c3c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and store model card\n",
    "from MachineLearningModels.ModelCardMaker import create_model_card\n",
    "import pandas as pd\n",
    "\n",
    "model_name = \"Augmented Logistic Regression for Synthetic Data Augmentation\"\n",
    "overview = \"Name of relevant dataset is \" + dataset_name + \", this ML model was trained to classify the target value of \" + target\n",
    "preproc_file = \"DataPrepMultiClassv1.py\"\n",
    "train_set_name = \"augmented_trainVAEForestFINAL.csv\"\n",
    "test_set_name = \"test_setVAEForestFINAL.csv\"\n",
    "evaluation_metrics = metrics_augmented\n",
    "intended_use = \"Classify the target value of \" + target + \" as well as possible.\"\n",
    "ethical_bias_concerns = \"Works with data related to forest coverage which can potentially impact environmental policy.\"\n",
    "output_filename = \"OutputMaterials/ModelCards/LR_augmented_ModelCard.md\"\n",
    "\n",
    "create_model_card(model_name, overview, preproc_file, random_state,\n",
    "                  test_size, features, target, train_set_name, test_set_name,\n",
    "                  evaluation_metrics, intended_use, ethical_bias_concerns, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e7212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create README.txt file\n",
    "\n",
    "readme_content = f\"\"\"\n",
    "# Output Materials for Synthetic Data Generation Framework for the ForestType Dataset\n",
    "\n",
    "This folder contains all the output artifacts from the synthetic data generation and evaluation pipeline. These materials are designed to be self-contained and reproducible, and they can be zipped and shared with others for further analysis or deployment.\n",
    "\n",
    "## Contents\n",
    "\n",
    "- **Trained Models:**  \n",
    "  Trained machine learning models (Logistic Regression) saved as pickle files.\n",
    "  \n",
    "- **Configuration Files:**  \n",
    "  JSON files detailing the pipeline configuration, including dataset information, preprocessing steps, synthetic data generation parameters, and evaluation metrics.  \n",
    "  *Filename:* `VAEForestPipelineConfig.json`\n",
    "\n",
    "- **Model Cards:**  \n",
    "  Markdown files that document each model's details, including:\n",
    "  - Overview and intended use\n",
    "  - Dataset information (original vs. augmented)\n",
    "  - Preprocessing details\n",
    "  - Hyperparameters and training details\n",
    "  - Evaluation metrics and performance results\n",
    "  - Ethical and bias considerations\n",
    "\n",
    "- **Evaluation Outputs:**  \n",
    "  Files containing evaluation metrics.\n",
    "\n",
    "## How to Use\n",
    "\n",
    "1. **Review Configuration:**  \n",
    "   Open the configuration JSON files to see the exact parameters and settings used during the pipeline execution.\n",
    "\n",
    "2. **Examine Model Cards:**  \n",
    "   Each model card provides a detailed description of the corresponding model. Use these documents to understand how the model was trained, evaluated, and any known limitations or ethical concerns.\n",
    "\n",
    "3. **Load and Deploy Models:**  \n",
    "   Trained models can be loaded using joblib (or pickle). For example:\n",
    "   ```python\n",
    "   import joblib\n",
    "   model = joblib.load(\"model.pkl\")\n",
    "\"\"\"\n",
    "\n",
    "with open(\"OutputMaterials/README.txt\", \"w\") as file:\n",
    "    file.write(readme_content)\n",
    "    \n",
    "print(\"Content saved to README.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e1e0b",
   "metadata": {},
   "source": [
    "# 5. Deployment and Monitoring\n",
    "\n",
    "After validating that the machine learning model augmented with synthetic data performs positively on the test set, the next phase is deployment and continuous monitoring. For the **Forest Cover Type Dataset** the goal was to improve classification for **rare cover types (4 & 5) by boosting recall and F1‑score**. The deployment process must ensure that synthetic data augmentation does not introduce unintended distortions.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Points\n",
    "\n",
    "- **Model Integration:**  \n",
    "  - Save the trained **Logistic Regression v1.0** (including z‑score normalization, one‑hot encoding, and 1st/99th‑percentile outlier trimming) as a self‑contained artifact.  \n",
    "  - Document that synthetic augmentation was applied to enhance recall and F1‑score for cover types 4 and 5.\n",
    "\n",
    "- **Documentation of Augmentation:**  \n",
    "  - Record augmentation metadata:  \n",
    "    - Percentage increase in minority classes 4 & 5: **100 %**  \n",
    "    - Scaling factors for small classes: **2× (doubling)**  \n",
    "    - Parameters/settings for each augmentation step (e.g. VAE latent_dim=10, epochs=100; SMOTE k_neighbors=5)  \n",
    "  - Embed this metadata within the model artifact and reference it in the model card.\n",
    "\n",
    "- **Monitoring for Data Drift:**  \n",
    "  - Deploy on **AWS SageMaker** and track incoming data for shifts in feature distributions or class balance.  \n",
    "  - Monitoring routine should:  \n",
    "    - Track key metrics (recall, F1‑score) for **cover type 4**  \n",
    "    - Monitor the rate of **cover type 4** predictions and flag deviations from the expected ~0.5 % prevalence  \n",
    "    - Periodically run high‑value ecological scenarios through the pipeline to verify consistent performance  \n",
    "    - Trigger alerts or automated retraining if recall for cover type 4 falls below **0.40**\n",
    "\n",
    "- **Re‑Training and Version Control:**  \n",
    "  - On detected drift or performance degradation, rerun the full pipeline—including synthetic data generation—with updated data.  \n",
    "  - Replace older augmented datasets with new versions.  \n",
    "  - Use version control (e.g., **GitHub**) and metadata logs to ensure each retraining iteration is reproducible and auditable.\n",
    "\n",
    "- **A/B Testing & Resource Monitoring:**  \n",
    "  - Implement an A/B test to compare **Augmented Logistic Regression v1.0** vs. **Baseline Logistic Regression v0.9** before full rollout.  \n",
    "  - Continuously monitor system resources (latency < 200 ms per prediction, CPU < 70 %, memory < 2 GB) to ensure real‑time operational constraints are met.\n",
    "\n",
    "---\n",
    "\n",
    "*This template can be customized to fit your organization’s deployment workflows and monitoring infrastructure.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cc594",
   "metadata": {},
   "source": [
    "# 6. Documentation & Ethics Review\n",
    "\n",
    "Throughout the lifecycle of the model for predicting forest cover types—especially minority classes 4 (Cottonwood/Willow) and 5 (Aspen)—using the **Forest Cover Type Dataset**, detailed documentation and ethics reviews are integral to maintaining transparency, fairness, and regulatory compliance.\n",
    "\n",
    "---\n",
    "\n",
    "### Documentation\n",
    "\n",
    "- **Parameter & Process Logs:**  \n",
    "  - Record every step of data processing, model training, and synthetic augmentation, including:  \n",
    "    - **Scaling & normalization:** z‑score normalization of continuous features  \n",
    "    - **Encoding:** one‑hot encoding of wilderness areas and soil types  \n",
    "    - **Outlier removal:** 1st/99th‑percentile trimming by class  \n",
    "    - **Synthetic generation settings:** VAE (latent_dim=10, epochs=2), SMOTE (k_neighbors=5), augmentation ratio 2× for classes 4 & 5  \n",
    "\n",
    "- **Model Cards & Technical Reports:**  \n",
    "  - Produce a model card detailing:  \n",
    "    - Intended use cases (e.g. habitat mapping, fire‐management planning)  \n",
    "    - Performance metrics by cover type (precision, recall, F1)  \n",
    "    - Identified limitations (e.g. boundary shifts in synthetic samples)  \n",
    "    - Role and impact of synthetic augmentation on minority‐class recall  \n",
    "  - Include a README summarizing setup, usage instructions, and dependencies.\n",
    "\n",
    "---\n",
    "\n",
    "### Ethics Review\n",
    "\n",
    "- **Bias & Fairness Evaluation:**  \n",
    "  - Identify “sensitive” features (geospatial proxies: elevation, hydrology/roadway distances) and assess whether augmentation skews habitat representation.  \n",
    "  - Compute fairness metrics (distribution parity, equalized odds) across all cover types and flag any shifts in minority‐class prevalence.\n",
    "\n",
    "- **Privacy Considerations:**  \n",
    "  - Confirm dataset contains no PII/PHI; features are purely environmental.  \n",
    "  - Document that no additional privacy techniques were needed beyond anonymized original data.\n",
    "\n",
    "- **Transparency & Accountability:**  \n",
    "  - Log all decisions, rationales, and bias/fairness assessment results.  \n",
    "  - Document any mitigation steps (e.g. adjusting augmentation ratio) taken in response to ethical findings.\n",
    "\n",
    "---\n",
    "\n",
    "### Regulatory & Audit Readiness\n",
    "\n",
    "- Compile a comprehensive package covering:  \n",
    "  - Data preprocessing workflows  \n",
    "  - Synthetic data generation process  \n",
    "  - Model training and validation results  \n",
    "  - Deployment, monitoring, and drift‐detection procedures  \n",
    "- Ensure all artifacts, logs, and model cards are versioned (e.g. GitHub, MLflow) and accessible for audit.\n",
    "\n",
    "---\n",
    "\n",
    "*This template can be adapted to fit your organization’s documentation standards and ethics review processes.*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378e3b34",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "- The project overall was a huge success as the augmentation process helped improve recall for 3 of the 4 minority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c6877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT PIPELINE\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "#Copy this file over to OutputMaterials folder.\n",
    "\n",
    "#SAVE FILE FIRST\n",
    "source_file = \"VAEForest.ipynb\"  # Replace notebook's filename.\n",
    "destination_folder = \"OutputMaterials/\"\n",
    "\n",
    "destination_file = os.path.join(destination_folder, os.path.basename(source_file))\n",
    "shutil.copy(source_file, destination_file)\n",
    "\n",
    "print(f\"Notebook copied from {source_file} to {destination_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
